# 3.5 1次元データの(非)類似度

## 3.5.0 イントロダクション - データの類似性を測る

### 🎯 本節の学習目標

この節では、**データ同士がどれくらい似ているか**を数値で表す方法を学びます。

例えば、以下の3つのデータがあったとします。

- **A**: (3, 4, 5)
- **B**: (3, 4, 29)
- **C**: (9, -18, 8)

**「Aに似ているのは、BとCのどちらでしょうか?」**

この問いに答えるために、データ間の**類似度**や**非類似度**を測る指標を使います。データサイエンスでは、このような指標が非常に重要です。例えば以下のようになります。

- 推薦システム: 「あなたに似た嗜好を持つ人が好きな商品」を見つける
- クラスタリング: 「似たデータをグループ化」する
- 異常検知: 「通常のデータと大きく異なるデータ」を見つける

本節で学ぶ内容は、これらの応用の基礎となります。

---

### 📊 類似度と非類似度の違い

データを比較する指標には、大きく分けて2種類あります。

#### 1. **非類似度 (Dissimilarity)**
- 値が**大きいほど似ていない**
- 値が**小さいほど似ている**
- 例: 距離（ユークリッド距離、マンハッタン距離）
- 最小値は通常0（完全に同じ）

#### 2. **類似度 (Similarity)**
- 値が**大きいほど似ている**
- 値が**小さいほど似ていない**
- 例: コサイン類似度、相関係数
- 通常-1〜1の範囲（1が最も似ている）

---

### 📐 本節で学ぶ4つの指標

本節では、以下の4つの指標を学びます（**表3.5**）

| 名称 | 種類 | 値の範囲 | 特徴 |
|:-----|:-----|:---------|:-----|
| **ユークリッド距離** | 非類似度 | 0以上 | 最も基本的な距離。直線距離 |
| **マンハッタン距離** | 非類似度 | 0以上 | 碁盤目状に移動する距離 |
| **コサイン類似度** | 類似度 | -1〜1 | ベクトルの向きの類似性 |
| **相関係数** | 類似度 | -1〜1 | 直線的な関係の強さ |

**数学的定義（詳細は各セクションで解説）:**

$$
\begin{align}
\text{ユークリッド距離} &= \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2} \\
\text{マンハッタン距離} &= \sum_{i=1}^{n}|x_i - y_i| \\
\text{コサイン類似度} &= \frac{\sum_{i=1}^{n} x_i y_i}{\sqrt{\sum_{i=1}^{n} x_i^2}\sqrt{\sum_{i=1}^{n} y_i^2}} \\
\text{相関係数} &= \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}
\end{align}
$$

**初めて見る方へ:** 数式を見て不安になる必要はありません！これらの計算は、RやPythonの関数を使えば簡単にできます。各セクションで、数式の意味と使い方を丁寧に説明していきます。

---

### 🎨 3次元空間での視覚的理解

本節で扱う例（A, B, C）は要素数が3なので、3次元空間の座標として視覚化できます。

- **A**(3, 4, 5): x=3, y=4, z=5の点
- **B**(3, 4, 29): x=3, y=4, z=29の点
- **C**(9, -18, 8): x=9, y=-18, z=8の点

距離を測ることで、「空間内でどの点が近いか」がわかります。

**重要な注意:** 要素数が4以上になると図形的な理解は難しくなりますが、ここで紹介する指標は**何次元でも使えます**。データサイエンスでは、数百、数千次元のデータを扱うこともあります！

---

### 🖥️ 環境準備とパッケージ確認

本節で使用するパッケージを確認し、必要に応じてインストールします。

#### 作業ディレクトリの確認

まず、適切なディレクトリで作業していることを確認しましょう。

```bash
# 現在のディレクトリを確認
pwd

# 推奨ディレクトリに移動
cd /home/datasci/work

# 仮想環境の起動確認（プロンプトに(class)が表示されるはず）
venvc
```

#### Python: 必要なパッケージの確認

```bash
# NumPyのバージョン確認
python -c "import numpy; print(numpy.__version__)"

# SciPyのバージョン確認
python -c "import scipy; print(scipy.__version__)"
```

もしエラーが出た場合は、以下のコマンドでインストールしてください。

```bash
pip install numpy scipy pandas --break-system-packages
```

#### R: 必要なパッケージの確認

```bash
# Rを起動してパッケージを確認
Rscript -e "library(tidyverse); library(proxy)"
```

もしエラーが出た場合は、Rを起動してインストールしてください:

```r
install.packages("tidyverse")
install.packages("proxy")
```

---

### 🤖 GitHub Copilotの準備

本節では、各セクションの最後に**GitHub Copilot活用ガイド**を用意しています。

#### GitHub Copilotとは？

GitHub Copilotは、AIがコーディングをサポートしてくれるツールです。VS Codeの拡張機能として利用でき、以下のような支援を受けられます。

1. **コード補完**: コメントを書くと、それに対応するコードを提案
2. **コード説明**: 既存のコードの意味を説明
3. **エラー解決**: エラーメッセージから解決方法を提案
4. **コード改善**: より良い書き方を提案

#### 基本的な使い方

##### 1. Copilot Chat の起動

VS Codeで以下のいずれかの方法でCopilot Chatを開きます。

- サイドバーのチャットアイコンをクリック
- ショートカットキー: `Ctrl + Shift + I` (Windows/Linux)

##### 2. プロンプトの入力

Copilot Chatに質問や依頼を入力します。例:

```
Pythonで2つのリストのユークリッド距離を計算するコードを書いてください。
初心者向けで、コメント付きでお願いします。
```

##### 3. 生成されたコードの確認

Copilotが提案したコードを**必ず理解してから**使いましょう。わからない部分があれば、さらに質問します。

```
このコードの3行目は何をしていますか?
```

---

### ⚠️ AI協働学習の心構え

#### ✅ やるべきこと

1. **まず自分で考える**: 教材を読んで概念を理解する
2. **Copilotと対話する**: 質問しながら理解を深める
3. **生成されたコードを理解する**: 動かすだけでなく、なぜそう書くのかを理解
4. **実験する**: パラメータを変えて試してみる
5. **検証する**: 結果が正しいか確認する

#### ❌ 避けるべきこと

1. **丸投げ**: 「全部やって」では学習にならない
2. **コピペのみ**: 理解せずにコピーするのは危険
3. **無批判な受け入れ**: AIは間違うこともある
4. **依存**: 自分で考える力が育たない

---

### 📚 本節の学習の流れ

```
1. 各指標の概念を理解（3.5.1〜3.5.4）
   ↓
2. サンプルプログラムで実践（R/Python両方）
   ↓
3. GitHub Copilotで実験
   ↓
4. データフレームで一括計算（3.5.5）
   ↓
5. 統合演習で定着（3.5.6）
   ↓
6. チェックリストで確認（3.5.7）
```

---

### 🎓 学習のポイント

1. **4つの指標の違いを理解する**: それぞれの特徴と使い分け
2. **RとPython両方で実装できる**: 同じ処理を2つの言語で
3. **数式の意味を直感的に理解する**: 完全に理解できなくても大丈夫
4. **AIと協働する**: Copilotを学習のパートナーとして活用

---

それでは、最初の指標「ユークリッド距離」から学んでいきましょう！

---

## 3.5.1 ユークリッド距離 - 最も基本的な距離の測り方

### 📐 ユークリッド距離とは？

**ユークリッド距離**は、2点間の**直線距離**を測る最も基本的な方法です。日常生活で「距離」と言ったら、通常はこのユークリッド距離を指します。

#### 身近な例

- 地図上の2地点間の直線距離
- 定規で測った長さ
- 「鳥が飛ぶ距離」

---

### 🎯 ピタゴラスの定理を使った計算

2次元（平面）の場合、2点 $(x_1, y_1)$ と $(x_2, y_2)$ の距離は、**ピタゴラスの定理**を使って計算できます。

$$
\text{距離} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}
$$

3次元の場合は、z座標も加えます。

$$
\text{距離} = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2}
$$

一般的に、n次元の場合、

$$
\text{ユークリッド距離} = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}
$$

**読み方**: 「各成分の差を2乗して、全部足して、平方根を取る」

---

### 💡 具体例で理解する

冒頭の3つのデータで考えてみましょう。

- **A**: (3, 4, 5)
- **B**: (3, 4, 29)
- **C**: (9, -18, 8)

#### AとBの距離を計算

1. 各成分の差を計算:
   - x: $3 - 3 = 0$
   - y: $4 - 4 = 0$
   - z: $29 - 5 = 24$

2. 差を2乗:
   - $0^2 = 0$
   - $0^2 = 0$
   - $24^2 = 576$

3. 合計して平方根:
   - $\sqrt{0 + 0 + 576} = \sqrt{576} = 24$

**AとBの距離は24**

#### AとCの距離を計算

1. 各成分の差:
   - x: $9 - 3 = 6$
   - y: $-18 - 4 = -22$
   - z: $8 - 5 = 3$

2. 差を2乗:
   - $6^2 = 36$
   - $(-22)^2 = 484$
   - $3^2 = 9$

3. 合計して平方根:
   - $\sqrt{36 + 484 + 9} = \sqrt{529} = 23$

**AとCの距離は23**

#### 結論

**AとCの距離（23）< AとBの距離（24）**

→ ユークリッド距離で測ると、**Aに似ているのはC**です。

---

### 💻 サンプルプログラム1: 基本的な計算（R）

**ファイル名**: `sample01_euclidean.R`

```r
# ユークリッド距離の基本計算

# 3つのデータを定義
A <- c(3,  4,  5)
B <- c(3,  4, 29)
C <- c(9, -18,  8)

# AとBの差を計算
AB <- B - A
print("AとBの差:")
print(AB)

# AとCの差を計算
AC <- C - A
print("AとCの差:")
print(AC)

# ユークリッド距離を計算
# 方法: 差を2乗 → 合計 → 平方根
distance_AB <- sum(AB^2)^0.5
distance_AC <- sum(AC^2)^0.5

# 結果を表示
print(paste("AとBのユークリッド距離:", distance_AB))
print(paste("AとCのユークリッド距離:", distance_AC))

# どちらがAに近いか判定
if (distance_AB < distance_AC) {
  print("結論: Aに似ているのはB")
} else {
  print("結論: Aに似ているのはC")
}
```

**実行方法**:

```bash
Rscript sample01_euclidean.R
```

**期待される出力**:

```
[1] "AとBの差:"
[1]  0  0 24
[1] "AとCの差:"
[1]   6 -22   3
[1] "AとBのユークリッド距離: 24"
[1] "AとCのユークリッド距離: 23"
[1] "結論: Aに似ているのはC"
```

---

### 💻 サンプルプログラム2: 基本的な計算（Python）

**ファイル名**: `sample01_euclidean.py`

```python
# ユークリッド距離の基本計算
import numpy as np
from scipy.spatial import distance

# 3つのデータを定義
A = np.array([3,  4,  5])
B = np.array([3,  4, 29])
C = np.array([9, -18,  8])

# ユークリッド距離を計算
distance_AB = distance.euclidean(A, B)
distance_AC = distance.euclidean(A, C)

# 結果を表示
print(f"AとBのユークリッド距離: {distance_AB}")
print(f"AとCのユークリッド距離: {distance_AC}")

# どちらがAに近いか判定
if distance_AB < distance_AC:
    print("結論: Aに似ているのはB")
else:
    print("結論: Aに似ているのはC")
```

**実行方法**:

```bash
python sample01_euclidean.py
```

**期待される出力**:

```
AとBのユークリッド距離: 24.0
AとCのユークリッド距離: 23.0
結論: Aに似ているのはC
```

---

### 🔍 R vs Python の比較

| 項目 | R | Python |
|:-----|:--|:-------|
| **配列の定義** | `c(3, 4, 5)` | `np.array([3, 4, 5])` |
| **差の計算** | `B - A`（自動） | `B - A`（NumPy配列なら自動） |
| **2乗** | `AB^2` | `AB**2` |
| **合計** | `sum()` | `np.sum()` または `.sum()` |
| **平方根** | `^0.5` または `sqrt()` | `**0.5` または `np.sqrt()` |
| **専用関数** | なし（手動計算） | `distance.euclidean()` |

**Python の利点**: `scipy.spatial.distance`に便利な関数が多数ある
**R の利点**: ベクトル演算がシンプルで直感的

---

### 📚 参考: より実践的な書き方

ここまでの基本版で十分ですが、**意欲的な学生向け**に、関数化した書き方も紹介します。

**現時点では基本版で十分です。**以下は参考として眺めるだけで構いません。

#### 発展版（R）

**ファイル名**: `sample01_advanced.R`

```r
# ユークリッド距離を計算する関数
euclidean_distance <- function(x, y) {
  # 入力チェック
  if (length(x) != length(y)) {
    stop("xとyの要素数が異なります")
  }
  
  # 距離計算
  diff <- y - x
  distance <- sum(diff^2)^0.5
  
  return(distance)
}

# データ定義
A <- c(3,  4,  5)
B <- c(3,  4, 29)
C <- c(9, -18,  8)

# 関数を使って計算
distance_AB <- euclidean_distance(A, B)
distance_AC <- euclidean_distance(A, C)

# 結果表示
cat(sprintf("AとBの距離: %.2f\n", distance_AB))
cat(sprintf("AとCの距離: %.2f\n", distance_AC))

# 比較
if (distance_AB < distance_AC) {
  cat("結論: Aに似ているのはB\n")
} else {
  cat("結論: Aに似ているのはC\n")
}
```

#### 発展版（Python）

**ファイル名**: `sample01_advanced.py`

```python
import numpy as np
from typing import Union

def euclidean_distance(x: np.ndarray, y: np.ndarray) -> float:
    """
    2つのベクトル間のユークリッド距離を計算
    
    Parameters:
    -----------
    x : np.ndarray
        1次元配列
    y : np.ndarray
        1次元配列（xと同じ長さ）
    
    Returns:
    --------
    float
        ユークリッド距離
    """
    if len(x) != len(y):
        raise ValueError("xとyの要素数が異なります")
    
    diff = y - x
    distance = np.sqrt(np.sum(diff ** 2))
    
    return distance

def main():
    # データ定義
    A = np.array([3,  4,  5])
    B = np.array([3,  4, 29])
    C = np.array([9, -18,  8])
    
    # 距離計算
    distance_AB = euclidean_distance(A, B)
    distance_AC = euclidean_distance(A, C)
    
    # 結果表示
    print(f"AとBの距離: {distance_AB:.2f}")
    print(f"AとCの距離: {distance_AC:.2f}")
    
    # 比較
    if distance_AB < distance_AC:
        print("結論: Aに似ているのはB")
    else:
        print("結論: Aに似ているのはC")

if __name__ == "__main__":
    main()
```

**発展版の特徴**:
- 関数として再利用可能
- エラーチェック付き
- 型ヒント（Python）やdocstring付き
- より保守しやすいコード

**学習段階**: これらは将来的に学ぶ内容です。今は基本版に集中しましょう！

---

### 💡 GitHub Copilot活用ガイド

ユークリッド距離の計算を通して、GitHub Copilotの使い方を実践してみましょう。Copilotは、あなたのプログラミング学習をサポートする強力なパートナーです。

---

#### 🚀 使えるプロンプト例

##### プロンプト例1: 基本的な距離計算 [★☆☆]

**Copilot Chatに入力**:
```
Pythonで2つのリスト [1, 2, 3] と [4, 5, 6] のユークリッド距離を計算するコードを書いてください。
初心者向けで、各ステップにコメントを付けてください。
NumPyを使ってください。
```

**期待される動作**:
- NumPyを使った配列定義のコードが生成される
- 差の計算、2乗、合計、平方根の各ステップが明確
- コメントが日本語または英語で付く

**確認事項**:
1. 上記のプロンプトをCopilot Chatに入力
2. 生成されたコードを新しいファイル（例: `test_euclidean.py`）にコピー
3. 実行して結果を確認: `python test_euclidean.py`
4. リストの値を変えて再実行してみる

---

##### プロンプト例2: 複数のデータの比較 [★★☆]

**Copilot Chatに入力**:
```
Rで3つのベクトル A, B, C があります。
A = c(1, 2, 3)
B = c(1, 2, 10)
C = c(5, 5, 5)
AとB、AとCのユークリッド距離を計算して、どちらがAに近いか判定するコードを書いてください。
```

**期待される動作**:
- 3つのベクトルを定義するコード
- 2つの距離を計算するコード
- if文で比較して結果を表示するコード

**確認事項**:
1. プロンプトをCopilot Chatに入力
2. 生成されたコードを `test_compare.R` として保存
3. 実行: `Rscript test_compare.R`
4. ベクトルの値を変えて、結果がどう変わるか実験

---

##### プロンプト例3: 手動計算の実装 [★★☆]

**Copilot Chatに入力**:
```
Pythonでユークリッド距離を手動で計算するコードを書いてください。
scipyやライブラリの関数は使わず、for文と数式を使って実装してください。
2つのリストを引数として受け取る形式でお願いします。
```

**期待される動作**:
- for文を使った要素ごとの差の計算
- 数式に忠実な実装
- ライブラリに頼らない基本的なコード

**確認事項**:
1. プロンプトを入力して、手動実装のコードを取得
2. `sample01_euclidean.py`の`distance.euclidean()`と比較
3. 両方の方法で同じ結果が得られることを確認
4. どちらが読みやすいか、使いやすいか考えてみる

---

#### 📚 Copilot活用のコツ

##### 1. **コメントを先に書く**

コードを書く前に、日本語のコメントで「何をしたいか」を書いてみましょう。

```python
# 2つのベクトルのユークリッド距離を計算
# ステップ1: ベクトルの差を計算
# ステップ2: 差を2乗
# ステップ3: 合計して平方根
```

このようにコメントを書くと、Copilotが自動的にコードを提案してくれることがあります！

##### 2. **段階的に書く**

一度に全部を書こうとせず、少しずつ書いて確認しましょう。

```python
# まず配列を定義
import numpy as np
A = np.array([3, 4, 5])

# 次に差を計算
# （Copilotが続きを提案してくれます）
```

##### 3. **生成されたコードを必ず理解する**

Copilotが提案したコードは、実行する前に必ず読んで理解しましょう。わからない部分があれば、Copilotに質問します。

```
このコードの `np.sqrt(np.sum(diff**2))` の部分を詳しく説明してください。
```

##### 4. **実験する**

生成されたコードのパラメータを変えて、どうなるか実験してみましょう。

- ベクトルの長さを変える
- 要素の値を変える
- 次元を増やす（4次元、5次元など）

---

#### ⚠️ 注意事項

##### **AIは完璧ではない**
Copilotが生成したコードにもエラーがあることがあります。必ず実行して確認しましょう。

##### **理解が第一**
コピペだけで済ませると、応用が効きません。「なぜそう書くのか」を理解することが大切です。

##### **検証する習慣**
- 期待通りの結果が出ているか確認
- 異なる入力でテスト
- エラーが出たら原因を調べる

##### **自分で考える**
困ったらすぐにCopilotに頼るのではなく、まず自分で考えてみましょう。それでもわからない時に質問するのがベストです。

---

#### 🎓 推奨される学習の流れ

```
1. 教材（このセクション）を読んで概念を理解
   ↓
2. サンプルプログラムを実行して動作確認
   ↓
3. 自分で似たようなプログラムを書いてみる
   ↓
4. 困ったらCopilotに聞く（上記のプロンプト例を参考に）
   ↓
5. 生成されたコードを理解して実験
   ↓
6. 練習問題で定着
```

**大切なのは「AIと協働する」姿勢です。丸投げではなく、一緒に学ぶパートナーとして活用しましょう！**

---

## 3.5.2 マンハッタン距離 - 碁盤目状の距離

### 🏙️ マンハッタン距離とは？

**マンハッタン距離**は、碁盤の目のような道を移動する距離です。別名「**タクシー距離**」や「**シティブロック距離**」とも呼ばれます。

#### なぜ「マンハッタン」？

ニューヨークのマンハッタンは、道が碁盤の目のように配置されています。タクシーで移動する時、斜めに走ることはできず、**縦と横にしか移動できません**。この移動距離がマンハッタン距離です。

#### 日常の例

- 都市部での実際の移動距離
- 碁盤上での駒の移動
- ブロックを数えて測る距離

---

### 📐 ユークリッド距離との違い

2点間の距離を測る方法は複数あります。

| 距離の種類 | 移動方法 | 特徴 |
|:----------|:--------|:-----|
| **ユークリッド距離** | 直線（斜め可） | 「鳥が飛ぶ距離」 |
| **マンハッタン距離** | 縦と横のみ | 「タクシーで移動する距離」 |

**視覚的な例**（2次元の場合）:

点A(0, 0)から点B(3, 4)への距離:

```
ユークリッド距離 = √(3² + 4²) = √25 = 5

マンハッタン距離 = |3| + |4| = 7
（右に3、上に4移動）
```

---

### 🎯 数学的定義

n次元の2点 $x = (x_1, x_2, \ldots, x_n)$ と $y = (y_1, y_2, \ldots, y_n)$ のマンハッタン距離は:

$$
\text{マンハッタン距離} = \sum_{i=1}^{n}|x_i - y_i|
$$

**読み方**: 「各成分の差の**絶対値**を全部足す」

---

### 💡 具体例で理解する

冒頭の3つのデータで計算してみましょう。

- **A**: (3, 4, 5)
- **B**: (3, 4, 29)
- **C**: (9, -18, 8)

#### AとBの距離

1. 各成分の差:
   - $|3 - 3| = 0$
   - $|4 - 4| = 0$
   - $|29 - 5| = 24$

2. 合計:
   - $0 + 0 + 24 = 24$

**AとBのマンハッタン距離は24**

#### AとCの距離

1. 各成分の差の絶対値:
   - $|9 - 3| = 6$
   - $|-18 - 4| = |-22| = 22$
   - $|8 - 5| = 3$

2. 合計:
   - $6 + 22 + 3 = 31$

**AとCのマンハッタン距離は31**

#### 結論

**AとBの距離（24）< AとCの距離（31）**

→ マンハッタン距離で測ると、**Aに似ているのはB**です。

**注目**: ユークリッド距離では「Aに似ているのはC」でしたが、マンハッタン距離では**結果が逆転**しました！使う指標によって、結論が変わることがあるのです。

---

### 💻 サンプルプログラム3: マンハッタン距離（R）

**ファイル名**: `sample02_manhattan.R`

```r
# マンハッタン距離の計算

# 3つのデータを定義
A <- c(3,  4,  5)
B <- c(3,  4, 29)
C <- c(9, -18,  8)

# AとBの差を計算
AB <- B - A
# AとCの差を計算
AC <- C - A

# マンハッタン距離を計算
# 方法: 差の絶対値を合計
distance_AB <- sum(abs(AB))
distance_AC <- sum(abs(AC))

# 結果を表示
print(paste("AとBのマンハッタン距離:", distance_AB))
print(paste("AとCのマンハッタン距離:", distance_AC))

# どちらがAに近いか判定
if (distance_AB < distance_AC) {
  print("結論: Aに似ているのはB")
} else {
  print("結論: Aに似ているのはC")
}

# 参考: ユークリッド距離と比較
euclidean_AB <- sum(AB^2)^0.5
euclidean_AC <- sum(AC^2)^0.5
print("--- ユークリッド距離との比較 ---")
print(paste("ユークリッド: AB =", euclidean_AB, ", AC =", euclidean_AC))
print(paste("マンハッタン: AB =", distance_AB, ", AC =", distance_AC))
```

**実行方法**:

```bash
Rscript sample02_manhattan.R
```

**期待される出力**:

```
[1] "AとBのマンハッタン距離: 24"
[1] "AとCのマンハッタン距離: 31"
[1] "結論: Aに似ているのはB"
[1] "--- ユークリッド距離との比較 ---"
[1] "ユークリッド: AB = 24 , AC = 23"
[1] "マンハッタン: AB = 24 , AC = 31"
```

---

### 💻 サンプルプログラム4: マンハッタン距離（Python）

**ファイル名**: `sample02_manhattan.py`

```python
# マンハッタン距離の計算
import numpy as np
from scipy.spatial import distance

# 3つのデータを定義
A = np.array([3,  4,  5])
B = np.array([3,  4, 29])
C = np.array([9, -18,  8])

# マンハッタン距離を計算
# cityblock = マンハッタン距離の別名
distance_AB = distance.cityblock(A, B)
distance_AC = distance.cityblock(A, C)

# 結果を表示
print(f"AとBのマンハッタン距離: {distance_AB}")
print(f"AとCのマンハッタン距離: {distance_AC}")

# どちらがAに近いか判定
if distance_AB < distance_AC:
    print("結論: Aに似ているのはB")
else:
    print("結論: Aに似ているのはC")

# 参考: ユークリッド距離と比較
euclidean_AB = distance.euclidean(A, B)
euclidean_AC = distance.euclidean(A, C)
print("\n--- ユークリッド距離との比較 ---")
print(f"ユークリッド: AB = {euclidean_AB}, AC = {euclidean_AC}")
print(f"マンハッタン: AB = {distance_AB}, AC = {distance_AC}")
```

**実行方法**:

```bash
python sample02_manhattan.py
```

**期待される出力**:

```
AとBのマンハッタン距離: 24
AとCのマンハッタン距離: 31
結論: Aに似ているのはB

--- ユークリッド距離との比較 ---
ユークリッド: AB = 24.0, AC = 23.0
マンハッタン: AB = 24, AC = 31
```

---

### 🔍 2つの距離の比較

| 項目 | ユークリッド距離 | マンハッタン距離 |
|:-----|:----------------|:----------------|
| **計算式** | $\sqrt{\sum(x_i - y_i)^2}$ | $\sum |x_i - y_i|$ |
| **R実装** | `sum(diff^2)^0.5` | `sum(abs(diff))` |
| **Python実装** | `distance.euclidean()` | `distance.cityblock()` |
| **特徴** | 斜め移動可能 | 縦横のみ移動 |
| **用途** | 一般的な距離 | 碁盤目状の構造 |
| **AB距離** | 24 | 24 |
| **AC距離** | 23 | 31 |
| **結論** | Cが近い | Bが近い |

---

### 📊 どちらを使うべき？

#### ユークリッド距離が適している場合
- 物理的な直線距離を測りたい時
- 空間内の点の近さを評価する時
- 画像認識、顔認識など

#### マンハッタン距離が適している場合
- 都市部での移動距離を測りたい時
- 碁盤目状の構造を持つデータ
- 外れ値の影響を抑えたい時（2乗しないため）
- 計算コストを抑えたい時（平方根が不要）

**どちらが正しいというわけではありません。** 問題に応じて適切な指標を選ぶことが大切です。

---

### 💡 GitHub Copilot活用ガイド

マンハッタン距離の理解を深めるために、Copilotを活用してさまざまな実験をしてみましょう。

---

#### 🚀 使えるプロンプト例

##### プロンプト例1: 基本的な実装 [★☆☆]

**Copilot Chatに入力**:
```
Pythonでマンハッタン距離を計算するコードを書いてください。
2つのリスト [1, 2, 3] と [4, 5, 6] を使います。
scipyは使わず、基本的な計算で実装してください。
各ステップにコメントを付けてください。
```

**期待される動作**:
- 2つのリストを定義
- 要素ごとの差の絶対値を計算
- 合計してマンハッタン距離を出力

**確認事項**:
1. プロンプトをCopilot Chatに入力
2. 生成されたコードを `test_manhattan.py` として保存
3. 実行して、`scipy.spatial.distance.cityblock()` と同じ結果になるか確認

---

##### プロンプト例2: ユークリッド距離との比較 [★★☆]

**Copilot Chatに入力**:
```
Rで2つのベクトルについて、ユークリッド距離とマンハッタン距離の両方を計算し、
結果を比較するコードを書いてください。
ベクトルA = c(0, 0, 0), ベクトルB = c(3, 4, 0)を使います。
```

**期待される動作**:
- 2つのベクトルを定義
- 両方の距離を計算
- 結果を並べて表示

**確認事項**:
1. コードを生成して実行
2. ベクトルBの値を変えて、どちらの距離が大きくなるか実験
3. 両者の差が大きくなるのはどんな場合か考察

---

##### プロンプト例3: 可視化 [★★★]

**Copilot Chatに入力**:
```
Pythonで2次元の2点間について、ユークリッド距離とマンハッタン距離を
図で比較するコードを書いてください。
matplotlibを使って、直線経路と碁盤目経路を描画してください。
点A(0,0)と点B(3,4)を使います。
```

**期待される動作**:
- matplotlibでグラフを描画
- 直線経路（ユークリッド）を描画
- 碁盤目経路（マンハッタン）を描画
- 両者の違いが視覚的にわかる

**確認事項**:
1. コードを生成して実行
2. 点Bの座標を変えて、経路の違いを観察
3. どんな場合に2つの距離が大きく異なるか考える

---

#### 📚 Copilot活用のコツ

##### 1. **計算の各ステップを確認**

```python
# まず差を計算
diff = B - A
print("差:", diff)

# 次に絶対値
abs_diff = abs(diff)
print("絶対値:", abs_diff)

# 最後に合計
manhattan = sum(abs_diff)
print("マンハッタン距離:", manhattan)
```

このように段階的に出力すると、計算が正しいか確認しやすくなります。

##### 2. **異なる実装方法を試す**

Copilotに「別の方法で実装してください」と依頼すると、異なるアプローチを提案してくれます。

```
マンハッタン距離を計算する別の方法を3つ教えてください。
```

##### 3. **エラーの解決**

エラーが出た時は、エラーメッセージをそのままCopilotに貼り付けて質問します。

```
このエラーが出ました:
TypeError: unsupported operand type(s) for -: 'list' and 'list'

どう修正すればいいですか?
```

##### 4. **概念の理解**

計算だけでなく、概念の理解もCopilotに聞けます。

```
マンハッタン距離とユークリッド距離は、どんな場合に結果が大きく異なりますか?
具体例を挙げて説明してください。
```

---

#### ⚠️ 注意事項

##### **関数名の違いに注意**
- Python: `distance.cityblock()` = マンハッタン距離
- R: `sum(abs(diff))` で手動計算が一般的

##### **絶対値を忘れずに**
マンハッタン距離では`abs()`（絶対値）が必須です。これを忘れると、負の値が出て間違った結果になります。

##### **次元数を確認**
2つのベクトルの要素数（次元）が一致していることを確認しましょう。

---

#### 🎓 推奨される学習の流れ

```
1. 2つの距離の違いを概念的に理解
   ↓
2. サンプルプログラムで両方を計算
   ↓
3. Copilotで異なる実装方法を試す
   ↓
4. 自分のデータで実験
   ↓
5. 結果の違いを考察
```

**マンハッタン距離の特性を理解したら、次は「類似度」の指標を学びましょう！**

---

## 3.5.3 コサイン類似度 - ベクトルの向きの類似性

### 📐 コサイン類似度とは？

これまでの2つ（ユークリッド距離、マンハッタン距離）は**非類似度**（距離）でしたが、ここからは**類似度**を学びます。

**コサイン類似度**は、2つのベクトルの**向き**がどれくらい似ているかを測る指標です。ベクトルの長さ（大きさ）は考慮せず、**方向だけ**に注目します。

#### 日常の例

- 「好きな映画ジャンル」の類似性を測る
  - 人A: (アクション:5, ロマンス:3, ホラー:1)
  - 人B: (アクション:10, ロマンス:6, ホラー:2)
  - 数値は違うが、**比率が同じ**（Bは全部2倍）→ 向きは同じ

- 文書の類似性判定（自然言語処理でよく使われる）

---

### 🎯 幾何学的な意味

コサイン類似度は、2つのベクトルが作る**角度θ（シータ）の余弦（コサイン）**です。

#### 角度と類似度の関係

| 角度θ | cos θ | 意味 |
|:------|:------|:-----|
| **0°** | **1** | 完全に同じ向き（最も類似） |
| **90°** | **0** | 直交（無関係） |
| **180°** | **-1** | 正反対の向き（最も非類似） |

**重要なポイント**: 
- 値の範囲: **-1 ≤ コサイン類似度 ≤ 1**
- 1に近いほど似ている
- -1に近いほど反対向き
- 0は無関係（直交）

---

### 📊 数学的定義

2つのベクトル $x = (x_1, x_2, \ldots, x_n)$ と $y = (y_1, y_2, \ldots, y_n)$ のコサイン類似度:

$$
\text{コサイン類似度} = \frac{x \cdot y}{||x|| \cdot ||y||} = \frac{\sum_{i=1}^{n} x_i y_i}{\sqrt{\sum_{i=1}^{n} x_i^2} \cdot \sqrt{\sum_{i=1}^{n} y_i^2}}
$$

**各要素の意味**:
- $x \cdot y$ : 内積（ベクトルの掛け算）
- $||x||$ : ベクトルxの長さ（ノルム）
- $||y||$ : ベクトルyの長さ（ノルム）

**読み方**: 「内積を、それぞれの長さの積で割る」

---

### 💡 計算の手順

#### 例: A(3, 4, 5)とB(3, 4, 29)のコサイン類似度

**ステップ1: 内積を計算**

$$
A \cdot B = (3 \times 3) + (4 \times 4) + (5 \times 29) = 9 + 16 + 145 = 170
$$

**ステップ2: 各ベクトルの長さを計算**

$$
||A|| = \sqrt{3^2 + 4^2 + 5^2} = \sqrt{9 + 16 + 25} = \sqrt{50} \approx 7.071
$$

$$
||B|| = \sqrt{3^2 + 4^2 + 29^2} = \sqrt{9 + 16 + 841} = \sqrt{866} \approx 29.428
$$

**ステップ3: コサイン類似度を計算**

$$
\text{コサイン類似度} = \frac{170}{7.071 \times 29.428} \approx \frac{170}{208.07} \approx 0.817
$$

**結果**: AとBのコサイン類似度は約**0.817**

---

### 🔍 具体例で理解する

冒頭の3つのデータで計算してみましょう。

- **A**: (3, 4, 5)
- **B**: (3, 4, 29)
- **C**: (9, -18, 8)

#### AとBのコサイン類似度

上記の計算より、約**0.817**

#### AとCのコサイン類似度

**ステップ1: 内積**
$$
A \cdot C = (3 \times 9) + (4 \times -18) + (5 \times 8) = 27 - 72 + 40 = -5
$$

**ステップ2: 長さ**
$$
||A|| = \sqrt{50} \approx 7.071
$$
$$
||C|| = \sqrt{9^2 + (-18)^2 + 8^2} = \sqrt{81 + 324 + 64} = \sqrt{469} \approx 21.656
$$

**ステップ3: コサイン類似度**
$$
\text{コサイン類似度} = \frac{-5}{7.071 \times 21.656} \approx \frac{-5}{153.15} \approx -0.033
$$

**結果**: AとCのコサイン類似度は約 **-0.033**

#### 結論

- **AとBのコサイン類似度**: 0.817（正の値、似た向き）
- **AとCのコサイン類似度**: -0.033（ほぼ0、ほぼ直交）

→ コサイン類似度で測ると、**Aに似ているのはB**です。

---

### 💻 サンプルプログラム5: コサイン類似度（R）

**ファイル名**: `sample03_cosine.R`

```r
# コサイン類似度の計算

# 3つのデータを定義
A <- c(3,  4,  5)
B <- c(3,  4, 29)
C <- c(9, -18,  8)

# コサイン類似度の計算式:
# (A・B) / (||A|| * ||B||)
# ・は内積、||A||はAの長さ

# AとBのコサイン類似度
# ステップ1: 内積を計算
dot_AB <- sum(A * B)
# ステップ2: それぞれの長さを計算
length_A <- sum(A * A)^0.5
length_B <- sum(B * B)^0.5
# ステップ3: コサイン類似度
cosine_AB <- dot_AB / (length_A * length_B)

# AとCのコサイン類似度
dot_AC <- sum(A * C)
length_C <- sum(C * C)^0.5
cosine_AC <- dot_AC / (length_A * length_C)

# 結果を表示
print(paste("AとBのコサイン類似度:", round(cosine_AB, 4)))
print(paste("AとCのコサイン類似度:", round(cosine_AC, 4)))

# どちらがAに似ているか判定
if (cosine_AB > cosine_AC) {
  print("結論: Aに似ているのはB")
} else {
  print("結論: Aに似ているのはC")
}
```

**実行方法**:

```bash
Rscript sample03_cosine.R
```

**期待される出力**:

```
[1] "AとBのコサイン類似度: 0.817"
[1] "AとCのコサイン類似度: -0.0327"
[1] "結論: Aに似ているのはB"
```

---

### 💻 サンプルプログラム6: コサイン類似度（Python）

**ファイル名**: `sample03_cosine.py`

```python
# コサイン類似度の計算
import numpy as np
from scipy.spatial import distance

# 3つのデータを定義
A = np.array([3,  4,  5])
B = np.array([3,  4, 29])
C = np.array([9, -18,  8])

# コサイン類似度を計算
# 注意: distance.cosine() は (1 - コサイン類似度) を返す
# したがって、1から引く必要がある
cosine_AB = 1 - distance.cosine(A, B)
cosine_AC = 1 - distance.cosine(A, C)

# 結果を表示
print(f"AとBのコサイン類似度: {cosine_AB:.4f}")
print(f"AとCのコサイン類似度: {cosine_AC:.4f}")

# どちらがAに似ているか判定
if cosine_AB > cosine_AC:
    print("結論: Aに似ているのはB")
else:
    print("結論: Aに似ているのはC")
```

**実行方法**:

```bash
python sample03_cosine.py
```

**期待される出力**:

```
AとBのコサイン類似度: 0.8170
AとCのコサイン類似度: -0.0327
結論: Aに似ているのはB
```

---

### ⚠️ 重要な注意: distance.cosineの挙動

**Python の `distance.cosine()` は「コサイン類似度」ではなく「コサイン距離」を返します。**

$$
\text{distance.cosine()} = 1 - \text{コサイン類似度}
$$

したがって、コサイン類似度を得るには**1から引く**必要があります。

```python
# ❌ 間違い
cosine_sim = distance.cosine(A, B)  # これは距離

# ✅ 正しい
cosine_sim = 1 - distance.cosine(A, B)  # これが類似度
```

---

### 🤔 「距離」という名前だが、実は距離ではない？

数学的に、**距離**は**三角不等式**を満たす必要があります。

$$
d(A, C) \leq d(A, B) + d(B, C)
$$

（A→Cの距離は、A→B→Cと経由する距離より短い）

しかし、コサイン距離は三角不等式を満たしません。実際に確認してみましょう。

```python
# コサイン距離で三角不等式を確認
d_AC = distance.cosine(A, C)
d_AB = distance.cosine(A, B)
d_BC = distance.cosine(B, C)

print(f"d(A,C) = {d_AC:.4f}")
print(f"d(A,B) + d(B,C) = {d_AB + d_BC:.4f}")
print(f"三角不等式を満たす? {d_AC <= d_AB + d_BC}")
# 出力: False
```

**結論**: コサイン距離を**非類似度**と考えるのは問題ありませんが、厳密な意味での**距離**とは考えないほうがよいでしょう。

---

### 🔄 コサイン類似度の特徴

#### 利点

1. **スケール不変**: ベクトルの大きさに影響されない
   - (1, 2, 3) と (10, 20, 30) のコサイン類似度は1（完全一致）

2. **高次元データに強い**: 次元が増えても計算が安定

3. **自然言語処理で頻用**: 文書の類似性判定など

#### 欠点

1. **大きさの情報を失う**: (1, 1) と (100, 100) を区別できない

2. **負の値の扱い**: 解釈が難しくなることがある

---

### 📚 参考: より実践的な書き方

**現時点では基本版で十分です。**以下は参考として眺めるだけで構いません。

#### 発展版（Python）

**ファイル名**: `sample03_advanced.py`

```python
import numpy as np
from scipy.spatial import distance
from typing import Tuple

def cosine_similarity(x: np.ndarray, y: np.ndarray) -> float:
    """
    2つのベクトルのコサイン類似度を計算
    
    Parameters:
    -----------
    x, y : np.ndarray
        1次元配列（同じ長さ）
    
    Returns:
    --------
    float
        コサイン類似度 (-1 ~ 1)
    """
    if len(x) != len(y):
        raise ValueError("ベクトルの長さが一致しません")
    
    # ゼロベクトルのチェック
    norm_x = np.linalg.norm(x)
    norm_y = np.linalg.norm(y)
    
    if norm_x == 0 or norm_y == 0:
        raise ValueError("ゼロベクトルはコサイン類似度を計算できません")
    
    # 内積 / (長さの積)
    return np.dot(x, y) / (norm_x * norm_y)

def compare_similarities(data_dict: dict) -> None:
    """
    複数のデータの類似度を比較
    
    Parameters:
    -----------
    data_dict : dict
        キー: データ名、値: ベクトル
    """
    names = list(data_dict.keys())
    
    print("=== コサイン類似度の比較 ===")
    for i in range(len(names)):
        for j in range(i+1, len(names)):
            name1, name2 = names[i], names[j]
            vec1, vec2 = data_dict[name1], data_dict[name2]
            
            sim = cosine_similarity(vec1, vec2)
            print(f"{name1} vs {name2}: {sim:.4f}")

def main():
    # データ定義
    data = {
        'A': np.array([3,  4,  5]),
        'B': np.array([3,  4, 29]),
        'C': np.array([9, -18,  8])
    }
    
    # 比較実行
    compare_similarities(data)
    
    # 参考: scipyとの比較
    print("\n=== scipy.spatial.distanceとの比較 ===")
    for i, name1 in enumerate(data.keys()):
        for name2 in list(data.keys())[i+1:]:
            sim_custom = cosine_similarity(data[name1], data[name2])
            sim_scipy = 1 - distance.cosine(data[name1], data[name2])
            print(f"{name1} vs {name2}: custom={sim_custom:.6f}, scipy={sim_scipy:.6f}")

if __name__ == "__main__":
    main()
```

**発展版の特徴**:
- エラーハンドリング（ゼロベクトルのチェック）
- 複数データの一括比較機能
- 型ヒントとdocstring
- 保守性の高い構造

---

### 💡 GitHub Copilot活用ガイド

コサイン類似度は概念的に少し難しいですが、Copilotと一緒に実験することで理解が深まります。

---

#### 🚀 使えるプロンプト例

##### プロンプト例1: 基本的な実装 [★☆☆]

**Copilot Chatに入力**:
```
Pythonでコサイン類似度を手動計算するコードを書いてください。
scipyは使わず、NumPyだけを使います。
2つのベクトル [1, 2, 3] と [4, 5, 6] を使います。
内積、ベクトルの長さ、類似度の各ステップを明示してください。
```

**期待される動作**:
- 内積の計算
- 各ベクトルの長さ（ノルム）の計算
- コサイン類似度の計算
- 各ステップの結果を出力

**確認事項**:
1. コードを生成して実行
2. ベクトルの値を変えて、類似度がどう変わるか観察
3. 片方のベクトルを2倍にしても類似度は変わらないことを確認

---

##### プロンプト例2: スケール不変性の実験 [★★☆]

**Copilot Chatに入力**:
```
Rでコサイン類似度のスケール不変性を確認するコードを書いてください。
ベクトルA = c(1, 2, 3)に対して、
ベクトルB = c(1, 2, 3)（同じ）
ベクトルC = c(10, 20, 30)（10倍）
ベクトルD = c(100, 200, 300)（100倍）
のコサイン類似度をそれぞれ計算してください。
```

**期待される動作**:
- 3つのベクトルとAの類似度を計算
- すべて1.0（完全一致）になることを確認
- スケール不変性を実証

**確認事項**:
1. コードを実行して、すべての類似度が1になることを確認
2. ユークリッド距離でも同じことをやってみる（こちらは変化する）
3. 2つの指標の違いを考察

---

##### プロンプト例3: 角度の可視化 [★★★]

**Copilot Chatに入力**:
```
Pythonで2次元ベクトルのコサイン類似度を視覚化するコードを書いてください。
ベクトルA = [3, 4]とベクトルB = [4, 3]を使います。
matplotlibで以下を描画してください:
1. 原点から2つのベクトルを矢印で描く
2. ベクトル間の角度を表示
3. コサイン類似度の値を表示
```

**期待される動作**:
- 2つのベクトルを矢印で描画
- 角度とコサイン類似度を計算して表示
- 視覚的に理解できる図

**確認事項**:
1. コードを生成して実行
2. ベクトルBの値を変えて、角度と類似度の関係を観察
3. 90度（直交）の時、類似度が0になることを確認

---

##### プロンプト例4: 推薦システムのシミュレーション [★★★]

**Copilot Chatに入力**:
```
Pythonでコサイン類似度を使った簡単な映画推薦システムを作ってください。
ユーザーA: [5, 3, 0, 1]（各数字は映画への評価）
ユーザーB: [4, 0, 0, 1]
ユーザーC: [1, 1, 0, 5]
ユーザーAと最も嗜好が似ているユーザーを見つけてください。
```

**期待される動作**:
- 3人のユーザーの評価ベクトルを定義
- AとB、AとCのコサイン類似度を計算
- 最も類似度が高いユーザーを特定

**確認事項**:
1. コードを実行して結果を確認
2. 評価を変えて、推薦結果がどう変わるか実験
3. 実際の推薦システムでの応用を考える

---

#### 📚 Copilot活用のコツ

##### 1. **数式を段階的に実装**

数式が複雑に見える時は、段階的に実装します。

```python
# ステップ1: 内積
dot_product = np.dot(A, B)
print(f"内積: {dot_product}")

# ステップ2: 長さ
norm_A = np.linalg.norm(A)
norm_B = np.linalg.norm(B)
print(f"Aの長さ: {norm_A}, Bの長さ: {norm_B}")

# ステップ3: コサイン類似度
cosine_sim = dot_product / (norm_A * norm_B)
print(f"コサイン類似度: {cosine_sim}")
```

##### 2. **特殊なケースを試す**

- 同じベクトル: 類似度は1
- 逆向きのベクトル: 類似度は-1
- 直交するベクトル: 類似度は0

```python
# Copilotに聞いてみる
# 「直交する2つのベクトルの例を作って、コサイン類似度が0になることを確認するコードを書いてください」
```

##### 3. **他の指標と比較**

```python
# 同じデータで、ユークリッド距離とコサイン類似度を比較
# どちらが適切か考察
```

##### 4. **実データで実験**

```python
# Copilotに聞く:
# 「テキストデータをベクトル化してコサイン類似度を計算する例を教えてください」
```

---

#### ⚠️ 注意事項

##### **1から引くのを忘れずに（Python）**
`distance.cosine()`を使う時は、必ず1から引いてコサイン類似度を得ます。

##### **ゼロベクトルに注意**
すべての要素が0のベクトルは、コサイン類似度を計算できません（長さが0なので割り算できない）。

##### **解釈の注意**
- コサイン類似度が高い = 向きが似ている
- ユークリッド距離が小さい = 位置が近い

この2つは別の概念です！

---

#### 🎓 推奨される学習の流れ

```
1. 内積とベクトルの長さの概念を復習
   ↓
2. 手動計算で数式の意味を理解
   ↓
3. サンプルプログラムで実装
   ↓
4. Copilotでスケール不変性を実験
   ↓
5. 可視化して直感的に理解
   ↓
6. 実際の応用例（推薦システムなど）を試す
```

**コサイン類似度は最初は難しく感じるかもしれませんが、実験を重ねることで理解が深まります！**

---

## 3.5.4 相関係数 - 直線的な関係の強さ

### 📊 相関係数とは？

**相関係数**（ピアソンの積率相関係数）は、2つのデータ間の**直線的な関係の強さ**を測る指標です。

コサイン類似度に似ていますが、相関係数は**平均値からのずれ**に注目します。

---

### 🎯 相関の種類

| 相関係数の値 | 意味 | 散布図のイメージ |
|:------------|:-----|:----------------|
| **1に近い** | 強い正の相関 | 右上がりの直線に近い |
| **0に近い** | 相関なし | バラバラに散らばる |
| **-1に近い** | 強い負の相関 | 右下がりの直線に近い |

#### 正の相関の例
- 身長と体重（身長が高いと体重も重い傾向）
- 勉強時間と成績（勉強時間が長いと成績が良い傾向）

#### 負の相関の例
- 運動時間と体脂肪率（運動が多いと体脂肪率が低い傾向）
- 価格と販売数（価格が高いと売れにくい傾向）

#### 相関なしの例
- 身長と数学の成績（特に関係がない）

---

### 📐 数学的定義

2つのベクトル $x = (x_1, x_2, \ldots, x_n)$ と $y = (y_1, y_2, \ldots, y_n)$ の相関係数:

$$
r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2} \cdot \sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}
$$

ここで:
- $\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$ : xの平均値
- $\bar{y} = \frac{1}{n}\sum_{i=1}^{n} y_i$ : yの平均値

**読み方**: 「平均からの偏差の積の和を、それぞれの標準偏差の積で割る」

---

### 🔍 コサイン類似度との違い

| 項目 | コサイン類似度 | 相関係数 |
|:-----|:--------------|:---------|
| **中心化** | しない | する（平均を引く） |
| **測るもの** | ベクトルの向き | 直線関係の強さ |
| **スケール** | 不変 | 不変 |
| **位置** | 考慮しない | 平均からの位置を考慮 |

**例**: データが全体的に大きい値でも小さい値でも、相関係数は変わりません。

---

### 💡 具体例で理解する

冒頭の3つのデータで計算してみましょう。

- **A**: (3, 4, 5)
- **B**: (3, 4, 29)
- **C**: (9, -18, 8)

#### AとBの相関係数

**ステップ1: 平均値を計算**
$$
\bar{A} = \frac{3 + 4 + 5}{3} = 4
$$
$$
\bar{B} = \frac{3 + 4 + 29}{3} = 12
$$

**ステップ2: 偏差を計算**
- A の偏差: $(3-4, 4-4, 5-4) = (-1, 0, 1)$
- B の偏差: $(3-12, 4-12, 29-12) = (-9, -8, 17)$

**ステップ3: 分子を計算**
$$
\sum(x_i - \bar{x})(y_i - \bar{y}) = (-1)(-9) + (0)(-8) + (1)(17) = 9 + 0 + 17 = 26
$$

**ステップ4: 分母を計算**
$$
\sqrt{\sum(x_i - \bar{x})^2} = \sqrt{(-1)^2 + 0^2 + 1^2} = \sqrt{2} \approx 1.414
$$
$$
\sqrt{\sum(y_i - \bar{y})^2} = \sqrt{(-9)^2 + (-8)^2 + 17^2} = \sqrt{81 + 64 + 289} = \sqrt{434} \approx 20.833
$$

**ステップ5: 相関係数**
$$
r = \frac{26}{1.414 \times 20.833} \approx \frac{26}{29.458} \approx 0.882
$$

**結果**: AとBの相関係数は約**0.882**

#### AとCの相関係数

計算手順は同じですが、結果は約**-0.033**となります（詳細は省略）。

#### 結論

- **AとBの相関係数**: 0.882（強い正の相関）
- **AとCの相関係数**: -0.033（ほぼ無相関）

→ 相関係数で測ると、**Aに似ているのはB**です。

---

### 💻 サンプルプログラム7: 相関係数（R）

**ファイル名**: `sample04_correlation.R`

```r
# 相関係数の計算

# 3つのデータを定義
A <- c(3,  4,  5)
B <- c(3,  4, 29)
C <- c(9, -18,  8)

# Rには便利なcor()関数がある
correlation_AB <- cor(A, B)
correlation_AC <- cor(A, C)

# 結果を表示
print(paste("AとBの相関係数:", round(correlation_AB, 4)))
print(paste("AとCの相関係数:", round(correlation_AC, 4)))

# どちらがAに似ているか判定
if (correlation_AB > correlation_AC) {
  print("結論: Aに似ているのはB")
} else {
  print("結論: Aに似ているのはC")
}

# 参考: 相関の強さの解釈
print("\n--- 相関の強さの解釈 ---")
interpret_correlation <- function(r) {
  abs_r <- abs(r)
  if (abs_r >= 0.7) {
    return("強い相関")
  } else if (abs_r >= 0.4) {
    return("中程度の相関")
  } else {
    return("弱い相関")
  }
}

print(paste("AとB:", interpret_correlation(correlation_AB)))
print(paste("AとC:", interpret_correlation(correlation_AC)))
```

**実行方法**:

```bash
Rscript sample04_correlation.R
```

**期待される出力**:

```
[1] "AとBの相関係数: 0.8825"
[1] "AとCの相関係数: -0.0327"
[1] "結論: Aに似ているのはB"

[1] "--- 相関の強さの解釈 ---"
[1] "AとB: 強い相関"
[1] "AとC: 弱い相関"
```

---

### 💻 サンプルプログラム8: 相関係数（Python）

**ファイル名**: `sample04_correlation.py`

```python
# 相関係数の計算
import numpy as np
from scipy.spatial import distance
from scipy.stats import pearsonr

# 3つのデータを定義
A = np.array([3,  4,  5])
B = np.array([3,  4, 29])
C = np.array([9, -18,  8])

# 方法1: distance.correlation（1から引く）
correlation_AB_1 = 1 - distance.correlation(A, B)
correlation_AC_1 = 1 - distance.correlation(A, C)

# 方法2: pearsonr（より一般的）
correlation_AB_2, p_value_AB = pearsonr(A, B)
correlation_AC_2, p_value_AC = pearsonr(A, C)

# 結果を表示（どちらの方法も同じ結果）
print(f"AとBの相関係数: {correlation_AB_2:.4f}")
print(f"AとCの相関係数: {correlation_AC_2:.4f}")

# どちらがAに似ているか判定
if correlation_AB_2 > correlation_AC_2:
    print("結論: Aに似ているのはB")
else:
    print("結論: Aに似ているのはC")

# 参考: 相関の強さの解釈
print("\n--- 相関の強さの解釈 ---")
def interpret_correlation(r):
    abs_r = abs(r)
    if abs_r >= 0.7:
        return "強い相関"
    elif abs_r >= 0.4:
        return "中程度の相関"
    else:
        return "弱い相関"

print(f"AとB: {interpret_correlation(correlation_AB_2)}")
print(f"AとC: {interpret_correlation(correlation_AC_2)}")
```

**実行方法**:

```bash
python sample04_correlation.py
```

**期待される出力**:

```
AとBの相関係数: 0.8825
AとCの相関係数: -0.0327
結論: Aに似ているのはB

--- 相関の強さの解釈 ---
AとB: 強い相関
AとC: 弱い相関
```

---

### ⚠️ 重要な注意: Pythonの2つの方法

Pythonで相関係数を計算する方法は2つあります。

#### 方法1: `distance.correlation()`

```python
# コサイン距離と同様、1から引く必要がある
correlation = 1 - distance.correlation(A, B)
```

#### 方法2: `pearsonr()`（推奨）

```python
# こちらの方が一般的で、p値も得られる
correlation, p_value = pearsonr(A, B)
```

**どちらを使う？**
- 単純に相関係数だけ欲しい → どちらでもOK
- 統計的な有意性も知りたい → `pearsonr()`を推奨

---

### 📊 相関係数の注意点

#### 1. **相関 ≠ 因果関係**

相関係数が高くても、因果関係があるとは限りません。

**例**: アイスクリームの売上と水難事故の件数には正の相関がありますが、因果関係はありません（どちらも気温が原因）。

#### 2. **直線関係のみ**

相関係数は**直線的な関係**しか測れません。

**例**: $y = x^2$ のような曲線関係では、相関係数は低くなります。

#### 3. **外れ値の影響**

1つの極端な値が相関係数を大きく変えることがあります。

---

### 💡 GitHub Copilot活用ガイド

相関係数は実務で非常によく使われる指標です。Copilotを活用して、さまざまなデータで実験してみましょう。

---

#### 🚀 使えるプロンプト例

##### プロンプト例1: 散布図と相関係数 [★★☆]

**Copilot Chatに入力**:
```
Pythonで2つのデータの相関係数を計算し、散布図を描くコードを書いてください。
x = [1, 2, 3, 4, 5]
y = [2, 4, 5, 4, 5]
matplotlibを使って、散布図に回帰直線も描いてください。
相関係数の値も図に表示してください。
```

**期待される動作**:
- 散布図の描画
- 回帰直線の追加
- 相関係数の計算と表示
- 視覚的に相関を理解できる

**確認事項**:
1. コードを生成して実行
2. yの値を変えて、相関係数がどう変わるか観察
3. 完全な正の相関（r=1）や負の相関（r=-1）を作ってみる

---

##### プロンプト例2: 相関係数の比較 [★★☆]

**Copilot Chatに入力**:
```
Rで3組のデータペアの相関係数を計算して比較するコードを書いてください。
ペア1: 強い正の相関
ペア2: 弱い相関
ペア3: 強い負の相関
それぞれのデータを作成して、相関係数を計算してください。
```

**期待される動作**:
- 異なる相関を持つ3組のデータを生成
- それぞれの相関係数を計算
- 結果を比較表示

**確認事項**:
1. 生成されたコードを実行
2. 各ペアのデータをプロットして視覚化
3. 相関係数の値と散布図の形の関係を観察

---

##### プロンプト例3: 外れ値の影響を実験 [★★★]

**Copilot Chatに入力**:
```
Pythonで外れ値が相関係数に与える影響を調べるコードを書いてください。
まず、強い正の相関を持つデータを作成します。
次に、1つの外れ値を追加して、相関係数がどう変わるか比較してください。
外れ値あり/なしの散布図を並べて表示してください。
```

**期待される動作**:
- 元のデータと外れ値入りデータを作成
- それぞれの相関係数を計算
- 2つの散布図を並べて表示
- 外れ値の影響を視覚化

**確認事項**:
1. コードを実行して、外れ値の影響を確認
2. 外れ値の位置や大きさを変えて実験
3. どんな場合に影響が大きいか考察

---

##### プロンプト例4: 実データでの応用 [★★★]

**Copilot Chatに入力**:
```
Pythonで架空の学生データを作成し、勉強時間と成績の相関を分析するコードを書いてください。
10人の学生について、勉強時間（時間）と成績（0-100点）のデータを作成し、
相関係数を計算して、散布図と回帰直線を描いてください。
```

**期待される動作**:
- 現実的なデータの生成
- 相関分析
- 視覚化
- 結果の解釈

**確認事項**:
1. コードを実行して結果を観察
2. データのパターンを変えて実験（例: 相関なし）
3. 実際の分析でどう使えるか考える

---

#### 📚 Copilot活用のコツ

##### 1. **視覚化と併用**

相関係数は数値だけ見ても理解しにくいので、必ず散布図も描きましょう。

```python
# Copilotに聞く
# 「相関係数を計算して散布図を描くコードを書いてください」
```

##### 2. **異なる相関パターンを作る**

```python
# 正の相関
x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

# 負の相関
y = [10, 8, 6, 4, 2]

# 無相関
y = [3, 7, 2, 9, 5]
```

##### 3. **p値も確認**

`pearsonr()`はp値も返します。これは相関が統計的に有意かを判断する指標です。

```python
corr, p_value = pearsonr(x, y)
if p_value < 0.05:
    print("統計的に有意な相関")
```

##### 4. **コサイン類似度との比較**

同じデータで両方を計算して、違いを理解しましょう。

```python
# Copilotに聞く
# 「同じデータでコサイン類似度と相関係数を計算し、違いを説明してください」
```

---

#### ⚠️ 注意事項

##### **相関と因果を混同しない**
相関係数が高くても、必ずしも因果関係があるわけではありません。

##### **非線形関係には不適**
曲線的な関係には、相関係数は低くなります。

##### **標本サイズの影響**
データ数が少ないと、偶然高い相関が出ることがあります。

---

#### 🎓 推奨される学習の流れ

```
1. 平均値と偏差の概念を復習
   ↓
2. 手動計算で数式の意味を理解
   ↓
3. サンプルプログラムで実装
   ↓
4. Copilotで散布図を作成
   ↓
5. 外れ値や非線形関係を実験
   ↓
6. 実データで分析練習
```

**相関係数は実務で最もよく使われる統計量の1つです。しっかり理解しておきましょう！**

---

## 3.5.5 データフレームを使う方法 - まとめて計算

### 🎯 複数データの一括比較

これまでは、A-B、A-Cのように**2つずつ**比較してきました。しかし、実際のデータ分析では、複数のデータを**一度に比較**したいことが多くあります。

例えば:
- 10個の商品の類似度を全ペアで計算
- 100人の顧客の類似度を全ペアで計算

こういう時に便利なのが、**データフレーム**を使った一括計算です。

---

### 📊 距離行列とは？

複数のデータ間の距離（または類似度）を表にしたものを**距離行列**といいます。

例: A、B、Cの3つのデータの距離行列

```
     A    B    C
A    0   24   23
B   24    0   31
C   23   31    0
```

**読み方**:
- 対角線（自分と自分）は常に0
- 対称（AとBの距離 = BとAの距離）
- 全ペアの関係が一目でわかる

---

### 💻 サンプルプログラム9: 一括計算（R）

**ファイル名**: `sample05_dataframe.R`

```r
# データフレームを使った(非)類似度の一括計算
library(tidyverse)
library(proxy)

# データフレームを作成
# 注意: 行名がA, B, Cになるように設定
my_df <- data.frame(
  x = c(3,  4,  5),
  y = c(3,  4, 29),
  z = c(9, -18,  8),
  row.names = c("A", "B", "C")
)

# データを確認
print("=== データ ===")
print(my_df)

# 1. ユークリッド距離
print("\n=== ユークリッド距離 ===")
euclidean_dist <- my_df %>% proxy::dist("Euclidean")
print(euclidean_dist)

# 2. マンハッタン距離
print("\n=== マンハッタン距離 ===")
manhattan_dist <- my_df %>% proxy::dist("Manhattan")
print(manhattan_dist)

# 3. コサイン類似度
print("\n=== コサイン類似度 ===")
cosine_sim <- my_df %>% proxy::simil("cosine")
print(cosine_sim)

# 4. 相関係数
print("\n=== 相関係数 ===")
correlation <- my_df %>% proxy::simil("correlation")
print(correlation)

# 結果の解釈
print("\n=== 結果の解釈 ===")
print("Aに最も似ているのは:")
print("- ユークリッド距離: C（距離23）")
print("- マンハッタン距離: B（距離24）")
print("- コサイン類似度: B（0.817）")
print("- 相関係数: B（0.882）")
```

**実行方法**:

```bash
Rscript sample05_dataframe.R
```

**期待される出力**:

```
=== データ ===
   x   y  z
A  3   3  9
B  4   4 -18
C  5  29  8

=== ユークリッド距離 ===
   A  B
B 24   
C 23 31

=== マンハッタン距離 ===
   A  B
B 24   
C 31 49

=== コサイン類似度 ===
          A         B
B 0.8169679          
C -0.0326512 0.2934244

=== 相関係数 ===
          A         B
B  0.8824975          
C -0.0326628  0.4412413

=== 結果の解釈 ===
[1] "Aに最も似ているのは:"
[1] "- ユークリッド距離: C（距離23）"
[1] "- マンハッタン距離: B（距離24）"
[1] "- コサイン類似度: B（0.817）"
[1] "- 相関係数: B（0.882）"
```

---

### 💻 サンプルプログラム10: 一括計算（Python）

**ファイル名**: `sample05_dataframe.py`

```python
# データフレームを使った(非)類似度の一括計算
import numpy as np
import pandas as pd
from scipy.spatial import distance

# 小数点以下3桁表示
np.set_printoptions(precision=3)

# データフレームを作成
my_df = pd.DataFrame({
    'x': [3,  4,  5],
    'y': [3,  4, 29],
    'z': [9, -18,  8]},
    index=['A', 'B', 'C']
)

# データを確認
print("=== データ ===")
print(my_df)

# 1. ユークリッド距離
print("\n=== ユークリッド距離 ===")
euclidean_dist = distance.cdist(my_df, my_df, metric='euclidean')
print(euclidean_dist)

# 2. マンハッタン距離
print("\n=== マンハッタン距離 ===")
manhattan_dist = distance.cdist(my_df, my_df, metric='cityblock')
print(manhattan_dist)

# 3. コサイン類似度
print("\n=== コサイン類似度 ===")
cosine_sim = 1 - distance.cdist(my_df, my_df, metric='cosine')
print(cosine_sim)

# 4. 相関係数
print("\n=== 相関係数 ===")
correlation = 1 - distance.cdist(my_df, my_df, metric='correlation')
print(correlation)

# 結果の解釈
print("\n=== 結果の解釈 ===")
print("Aに最も似ているのは:")
print("- ユークリッド距離: C（距離23）")
print("- マンハッタン距離: B（距離24）")
print("- コサイン類似度: B（0.817）")
print("- 相関係数: B（0.882）")
```

**実行方法**:

```bash
python sample05_dataframe.py
```

**期待される出力**:

```
=== データ ===
   x   y  z
A  3   3  9
B  4   4 -18
C  5  29  8

=== ユークリッド距離 ===
[[ 0. 24. 23.]
 [24.  0. 31.]
 [23. 31.  0.]]

=== マンハッタン距離 ===
[[ 0. 24. 31.]
 [24.  0. 49.]
 [31. 49.  0.]]

=== コサイン類似度 ===
[[ 1.    0.817 -0.033]
 [ 0.817  1.    0.293]
 [-0.033  0.293  1.   ]]

=== 相関係数 ===
[[ 1.    0.882 -0.033]
 [ 0.882  1.    0.441]
 [-0.033  0.441  1.   ]]

=== 結果の解釈 ===
Aに最も似ているのは:
- ユークリッド距離: C（距離23）
- マンハッタン距離: B（距離24）
- コサイン類似度: B（0.817）
- 相関係数: B（0.882）
```

---

### 🔍 R vs Python の比較

| 項目 | R | Python |
|:-----|:--|:-------|
| **ライブラリ** | `proxy` | `scipy.spatial.distance` |
| **距離計算** | `proxy::dist()` | `distance.cdist()` |
| **類似度計算** | `proxy::simil()` | `1 - distance.cdist()` |
| **出力形式** | 下三角行列 | 完全な行列 |
| **パイプ** | `%>%` 使用可 | メソッドチェーン |

---

### 📊 結果の読み方

#### Rの出力（下三角行列）

```
   A  B
B 24   
C 23 31
```

- 対角線より下だけ表示（対称なので上は省略）
- 読み方: AとBの距離は24、AとCは23、BとCは31

#### Pythonの出力（完全行列）

```
[[ 0. 24. 23.]
 [24.  0. 31.]
 [23. 31.  0.]]
```

- 完全な行列として表示
- 行: A, B, C / 列: A, B, C
- (0,1)要素 = AとBの距離 = 24

---

### 🎯 実践的な使い方

#### 最も似ているペアを見つける

```python
# ユークリッド距離で最も近いペアを見つける
# 対角線（自分と自分）を除く
min_dist = np.inf
min_pair = None

n = len(my_df)
for i in range(n):
    for j in range(i+1, n):
        dist = euclidean_dist[i, j]
        if dist < min_dist:
            min_dist = dist
            min_pair = (my_df.index[i], my_df.index[j])

print(f"最も近いペア: {min_pair}, 距離: {min_dist}")
```

---

### 📚 参考: より実践的な書き方

**現時点では基本版で十分です。**以下は参考として眺めるだけで構いません。

#### 発展版（Python）

**ファイル名**: `sample05_advanced.py`

```python
import numpy as np
import pandas as pd
from scipy.spatial import distance
from typing import Dict, Tuple
import matplotlib.pyplot as plt
import seaborn as sns

class SimilarityAnalyzer:
    """複数データの類似度を分析するクラス"""
    
    def __init__(self, data: pd.DataFrame):
        """
        Parameters:
        -----------
        data : pd.DataFrame
            行がデータ点、列が特徴量
        """
        self.data = data
        self.n = len(data)
        
    def compute_all_metrics(self) -> Dict[str, np.ndarray]:
        """全ての距離・類似度指標を計算"""
        metrics = {}
        
        # 距離
        metrics['euclidean'] = distance.cdist(
            self.data, self.data, metric='euclidean')
        metrics['manhattan'] = distance.cdist(
            self.data, self.data, metric='cityblock')
        
        # 類似度（1から引く必要がある）
        metrics['cosine'] = 1 - distance.cdist(
            self.data, self.data, metric='cosine')
        metrics['correlation'] = 1 - distance.cdist(
            self.data, self.data, metric='correlation')
        
        return metrics
    
    def find_most_similar(self, metric_name: str, 
                         is_similarity: bool = False) -> Tuple[str, str, float]:
        """
        最も類似したペアを見つける
        
        Parameters:
        -----------
        metric_name : str
            指標名（'euclidean', 'cosine'など）
        is_similarity : bool
            類似度かどうか（Trueなら最大値、Falseなら最小値を探す）
        """
        metrics = self.compute_all_metrics()
        matrix = metrics[metric_name]
        
        best_value = -np.inf if is_similarity else np.inf
        best_pair = None
        
        for i in range(self.n):
            for j in range(i+1, self.n):
                value = matrix[i, j]
                if (is_similarity and value > best_value) or \
                   (not is_similarity and value < best_value):
                    best_value = value
                    best_pair = (self.data.index[i], self.data.index[j])
        
        return best_pair[0], best_pair[1], best_value
    
    def visualize_heatmap(self, metric_name: str):
        """距離または類似度のヒートマップを描画"""
        metrics = self.compute_all_metrics()
        matrix = metrics[metric_name]
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(matrix, 
                    xticklabels=self.data.index,
                    yticklabels=self.data.index,
                    annot=True, 
                    fmt='.2f',
                    cmap='coolwarm',
                    center=0)
        plt.title(f'{metric_name.capitalize()} Matrix')
        plt.tight_layout()
        plt.savefig(f'{metric_name}_heatmap.png')
        print(f"ヒートマップを保存: {metric_name}_heatmap.png")
    
    def summarize(self):
        """全指標の結果を要約"""
        print("=== 類似度分析の要約 ===\n")
        
        distance_metrics = [
            ('euclidean', 'ユークリッド距離', False),
            ('manhattan', 'マンハッタン距離', False)
        ]
        
        similarity_metrics = [
            ('cosine', 'コサイン類似度', True),
            ('correlation', '相関係数', True)
        ]
        
        for metric, name, is_sim in distance_metrics + similarity_metrics:
            pair1, pair2, value = self.find_most_similar(metric, is_sim)
            print(f"{name}:")
            print(f"  最も{'類似' if is_sim else '近い'}ペア: {pair1} と {pair2}")
            print(f"  値: {value:.4f}\n")

def main():
    # データ作成
    my_df = pd.DataFrame({
        'x': [3,  4,  5],
        'y': [3,  4, 29],
        'z': [9, -18,  8]},
        index=['A', 'B', 'C']
    )
    
    # 分析実行
    analyzer = SimilarityAnalyzer(my_df)
    
    # 要約表示
    analyzer.summarize()
    
    # ヒートマップ作成
    for metric in ['euclidean', 'cosine']:
        analyzer.visualize_heatmap(metric)

if __name__ == "__main__":
    main()
```

**発展版の特徴**:
- クラスベースの設計
- 複数指標の一括処理
- ヒートマップの可視化
- エラーハンドリング
- 再利用可能な構造

---

### 💡 GitHub Copilot活用ガイド

データフレームを使った一括計算は、実際のデータ分析で非常によく使います。Copilotで効率的に学びましょう。

---

#### 🚀 使えるプロンプト例

##### プロンプト例1: 基本的な一括計算 [★★☆]

**Copilot Chatに入力**:
```
Pythonで5つのデータ点について、全ペアのユークリッド距離を計算するコードを書いてください。
データはランダムに生成してください。
結果をヒートマップで可視化してください。
```

**期待される動作**:
- ランダムなデータ生成
- distance.cdistで距離計算
- seabornでヒートマップ作成

**確認事項**:
1. コードを生成して実行
2. データ点の数を変えて実験
3. ヒートマップで近いペアを視覚的に特定

---

##### プロンプト例2: 最も類似したペアを見つける [★★☆]

**Copilot Chatに入力**:
```
Rでデータフレーム内の全ペアのコサイン類似度を計算し、
最も類似度が高いペアを自動的に見つけるコードを書いてください。
データは以下を使ってください:
A = c(1, 2, 3)
B = c(2, 4, 6)
C = c(1, 1, 1)
D = c(3, 2, 1)
```

**期待される動作**:
- 全ペアの類似度を計算
- 最大値を探索
- 結果を表示

**確認事項**:
1. コードを実行して最も類似したペアを確認
2. データを変えて結果がどう変わるか実験
3. 距離指標でも同様のコードを書いてみる

---

##### プロンプト例3: 複数指標の比較 [★★★]

**Copilot Chatに入力**:
```
Pythonで同じデータに対して、4つの指標
（ユークリッド距離、マンハッタン距離、コサイン類似度、相関係数）
を全て計算し、結果を4つのヒートマップで並べて表示するコードを書いてください。
```

**期待される動作**:
- 4つの指標を全て計算
- 2x2のサブプロットで4つのヒートマップ
- 各指標の違いが一目でわかる

**確認事項**:
1. コードを実行して4つの指標を比較
2. どの指標が似た結果を示すか観察
3. 指標による結論の違いを考察

---

##### プロンプト例4: クラスタリングへの応用 [★★★]

**Copilot Chatに入力**:
```
Pythonでユークリッド距離行列を使って、
階層的クラスタリングを実行し、デンドログラムを描くコードを書いてください。
10個のランダムなデータ点を使ってください。
```

**期待される動作**:
- 距離行列の計算
- scipy.cluster.hierarchyを使用
- デンドログラムの描画
- クラスタリング結果の可視化

**確認事項**:
1. コードを実行してクラスタリング結果を観察
2. 距離指標を変えて結果がどう変わるか実験
3. 本節の内容が次の分析にどう繋がるか理解

---

#### 📚 Copilot活用のコツ

##### 1. **データの形を確認**

```python
# データフレームの確認
print("データの形:", my_df.shape)
print("データの型:", my_df.dtypes)
print("データの内容:")
print(my_df)
```

##### 2. **段階的に計算**

```python
# まず1つの指標だけ計算
euclidean_dist = distance.cdist(my_df, my_df, metric='euclidean')

# 結果を確認してから次へ
print(euclidean_dist)

# 他の指標も追加
```

##### 3. **可視化で理解を深める**

```python
# Copilotに聞く
# 「距離行列をヒートマップで可視化するコードを書いてください」
```

##### 4. **エラーハンドリング**

```python
# データフレームの行数と列数が合っているか確認
if len(my_df) < 2:
    print("エラー: 少なくとも2つのデータが必要です")
```

---

#### ⚠️ 注意事項

##### **転置に注意（RとPythonで異なる）**

- **R**: データフレームの行が変数（A, B, C）
- **Python**: データフレームの行が変数、または列が変数（転置が必要な場合あり）

必要に応じて `my_df.T`（転置）を使います。

##### **距離と類似度を混同しない**

- 距離: 小さいほど近い
- 類似度: 大きいほど似ている

結果を解釈する時に注意しましょう。

##### **対称性**

距離・類似度行列は対称です（A→Bの距離 = B→Aの距離）。

---

#### 🎓 推奨される学習の流れ

```
1. 小さなデータで一括計算を実行
   ↓
2. 結果を行列として理解
   ↓
3. ヒートマップで可視化
   ↓
4. 最も類似/近いペアを自動検出
   ↓
5. 複数指標を比較
   ↓
6. クラスタリングなど次のステップへ
```

**データフレームを使った一括計算は、実務で頻繁に使う技術です。しっかりマスターしましょう！**

---

## 3.5.6 統合演習 - 実データで類似度を比較

### 🎯 演習の目的

本節で学んだ4つの指標を使って、実際のデータ分析を体験しましょう。この演習では:

1. 複数のデータについて、4つの指標を全て計算
2. 指標によって結論がどう変わるかを観察
3. 適切な指標の選び方を考察

---

### 📊 演習課題: 都市の気候データの類似性分析

#### 課題の概要

5つの都市の年間気候データ（月平均気温）があります。どの都市同士の気候が似ているかを、4つの指標を使って分析してください。

#### データ

各都市の12ヶ月の平均気温（℃）:

| 都市 | 1月 | 2月 | 3月 | 4月 | 5月 | 6月 | 7月 | 8月 | 9月 | 10月 | 11月 | 12月 |
|:-----|----:|----:|----:|----:|----:|----:|----:|----:|----:|-----:|-----:|-----:|
| **東京** | 5 | 6 | 9 | 14 | 19 | 22 | 26 | 27 | 23 | 18 | 12 | 7 |
| **札幌** | -4 | -3 | 1 | 7 | 13 | 17 | 21 | 22 | 18 | 11 | 4 | -1 |
| **那覇** | 17 | 17 | 19 | 22 | 25 | 28 | 29 | 29 | 27 | 25 | 21 | 18 |
| **ロンドン** | 5 | 5 | 7 | 9 | 13 | 16 | 18 | 18 | 15 | 11 | 8 | 5 |
| **シドニー** | 23 | 23 | 22 | 19 | 16 | 13 | 12 | 13 | 15 | 18 | 20 | 22 |

#### 求めること

1. 4つの指標（ユークリッド距離、マンハッタン距離、コサイン類似度、相関係数）を全て計算
2. 各指標で「東京に最も似ている都市」を特定
3. 指標によって結論がどう異なるかを考察
4. 結果をヒートマップで可視化（オプション）

---

### 💻 演習課題ファイル: Python版

**ファイル名**: `exercise01_similarity.py`

```python
# 演習課題: 都市の気候データの類似性分析
import numpy as np
import pandas as pd
from scipy.spatial import distance

# ========================================
# ステップ1: データの準備
# ========================================

# 各都市の月平均気温データ（12ヶ月分）
climate_data = pd.DataFrame({
    '東京':     [5,  6,  9, 14, 19, 22, 26, 27, 23, 18, 12,  7],
    '札幌':     [-4, -3,  1,  7, 13, 17, 21, 22, 18, 11,  4, -1],
    '那覇':     [17, 17, 19, 22, 25, 28, 29, 29, 27, 25, 21, 18],
    'ロンドン':  [5,  5,  7,  9, 13, 16, 18, 18, 15, 11,  8,  5],
    'シドニー':  [23, 23, 22, 19, 16, 13, 12, 13, 15, 18, 20, 22]
}, index=['1月', '2月', '3月', '4月', '5月', '6月', 
          '7月', '8月', '9月', '10月', '11月', '12月'])

print("=== 都市の気候データ（月平均気温） ===")
print(climate_data)
print()

# データを転置（都市を行、月を列にする）
climate_df = climate_data.T

# ========================================
# ステップ2: 4つの指標を計算
# ========================================

print("=== 各指標の計算結果 ===\n")

# 1. ユークリッド距離
print("1. ユークリッド距離")
euclidean_dist = distance.cdist(climate_df, climate_df, metric='euclidean')
euclidean_df = pd.DataFrame(euclidean_dist, 
                            index=climate_df.index, 
                            columns=climate_df.index)
print(euclidean_df.round(2))
print()

# 2. マンハッタン距離
print("2. マンハッタン距離")
manhattan_dist = distance.cdist(climate_df, climate_df, metric='cityblock')
manhattan_df = pd.DataFrame(manhattan_dist, 
                            index=climate_df.index, 
                            columns=climate_df.index)
print(manhattan_df.round(2))
print()

# 3. コサイン類似度
print("3. コサイン類似度")
cosine_sim = 1 - distance.cdist(climate_df, climate_df, metric='cosine')
cosine_df = pd.DataFrame(cosine_sim, 
                        index=climate_df.index, 
                        columns=climate_df.index)
print(cosine_df.round(4))
print()

# 4. 相関係数
print("4. 相関係数")
correlation = 1 - distance.cdist(climate_df, climate_df, metric='correlation')
correlation_df = pd.DataFrame(correlation, 
                              index=climate_df.index, 
                              columns=climate_df.index)
print(correlation_df.round(4))
print()

# ========================================
# ステップ3: 東京に最も似ている都市を特定
# ========================================

print("=== 東京に最も似ている都市 ===\n")

# 東京のデータを取得（自分自身を除く）
tokyo_euclidean = euclidean_df.loc['東京'].drop('東京')
tokyo_manhattan = manhattan_df.loc['東京'].drop('東京')
tokyo_cosine = cosine_df.loc['東京'].drop('東京')
tokyo_correlation = correlation_df.loc['東京'].drop('東京')

# 各指標で最も似ている都市
print(f"ユークリッド距離: {tokyo_euclidean.idxmin()} (距離: {tokyo_euclidean.min():.2f})")
print(f"マンハッタン距離: {tokyo_manhattan.idxmin()} (距離: {tokyo_manhattan.min():.2f})")
print(f"コサイン類似度: {tokyo_cosine.idxmax()} (類似度: {tokyo_cosine.max():.4f})")
print(f"相関係数: {tokyo_correlation.idxmax()} (相関: {tokyo_correlation.max():.4f})")
print()

# ========================================
# ステップ4: 考察（ここにあなたの考察を書いてください）
# ========================================

print("=== 考察 ===")
print("指標によって結果が異なる理由:")
print("- ユークリッド距離・マンハッタン距離: 気温の絶対値の差を測る")
print("- コサイン類似度: 気温変化のパターン（季節変動の形）を測る")
print("- 相関係数: 気温変化の傾向（平均からのずれの関係）を測る")
print()
print("あなたの考察をここに追加してください。")
```

**実行方法**:

```bash
python exercise01_similarity.py
```

---

### 💻 演習課題ファイル: R版

**ファイル名**: `exercise01_similarity.R`

```r
# 演習課題: 都市の気候データの類似性分析
library(tidyverse)
library(proxy)

# ========================================
# ステップ1: データの準備
# ========================================

# 各都市の月平均気温データ（12ヶ月分）
climate_data <- data.frame(
  '東京' = c(5,  6,  9, 14, 19, 22, 26, 27, 23, 18, 12,  7),
  '札幌' = c(-4, -3,  1,  7, 13, 17, 21, 22, 18, 11,  4, -1),
  '那覇' = c(17, 17, 19, 22, 25, 28, 29, 29, 27, 25, 21, 18),
  'ロンドン' = c(5,  5,  7,  9, 13, 16, 18, 18, 15, 11,  8,  5),
  'シドニー' = c(23, 23, 22, 19, 16, 13, 12, 13, 15, 18, 20, 22),
  row.names = c('1月', '2月', '3月', '4月', '5月', '6月', 
                '7月', '8月', '9月', '10月', '11月', '12月')
)

cat("=== 都市の気候データ（月平均気温） ===\n")
print(climate_data)
cat("\n")

# データを転置（都市を行、月を列にする）
climate_df <- t(climate_data)

# ========================================
# ステップ2: 4つの指標を計算
# ========================================

cat("=== 各指標の計算結果 ===\n\n")

# 1. ユークリッド距離
cat("1. ユークリッド距離\n")
euclidean_dist <- climate_df %>% proxy::dist("Euclidean")
print(euclidean_dist)
cat("\n")

# 2. マンハッタン距離
cat("2. マンハッタン距離\n")
manhattan_dist <- climate_df %>% proxy::dist("Manhattan")
print(manhattan_dist)
cat("\n")

# 3. コサイン類似度
cat("3. コサイン類似度\n")
cosine_sim <- climate_df %>% proxy::simil("cosine")
print(cosine_sim)
cat("\n")

# 4. 相関係数
cat("4. 相関係数\n")
correlation <- climate_df %>% proxy::simil("correlation")
print(correlation)
cat("\n")

# ========================================
# ステップ3: 東京に最も似ている都市を特定
# ========================================

cat("=== 東京に最も似ている都市 ===\n\n")

# 東京と他の都市の距離・類似度を抽出
# 注意: Rのdist/similオブジェクトは下三角行列なので、
# as.matrix()で完全な行列に変換してから処理

euclidean_matrix <- as.matrix(euclidean_dist)
manhattan_matrix <- as.matrix(manhattan_dist)
cosine_matrix <- as.matrix(cosine_sim)
correlation_matrix <- as.matrix(correlation)

# 東京の行を取得（自分自身を除く）
tokyo_euclidean <- euclidean_matrix["東京", ]
tokyo_euclidean <- tokyo_euclidean[names(tokyo_euclidean) != "東京"]

tokyo_manhattan <- manhattan_matrix["東京", ]
tokyo_manhattan <- tokyo_manhattan[names(tokyo_manhattan) != "東京"]

tokyo_cosine <- cosine_matrix["東京", ]
tokyo_cosine <- tokyo_cosine[names(tokyo_cosine) != "東京"]

tokyo_correlation <- correlation_matrix["東京", ]
tokyo_correlation <- tokyo_correlation[names(tokyo_correlation) != "東京"]

# 各指標で最も似ている都市
cat(sprintf("ユークリッド距離: %s (距離: %.2f)\n", 
            names(which.min(tokyo_euclidean)), 
            min(tokyo_euclidean)))

cat(sprintf("マンハッタン距離: %s (距離: %.2f)\n", 
            names(which.min(tokyo_manhattan)), 
            min(tokyo_manhattan)))

cat(sprintf("コサイン類似度: %s (類似度: %.4f)\n", 
            names(which.max(tokyo_cosine)), 
            max(tokyo_cosine)))

cat(sprintf("相関係数: %s (相関: %.4f)\n", 
            names(which.max(tokyo_correlation)), 
            max(tokyo_correlation)))

cat("\n")

# ========================================
# ステップ4: 考察（ここにあなたの考察を書いてください）
# ========================================

cat("=== 考察 ===\n")
cat("指標によって結果が異なる理由:\n")
cat("- ユークリッド距離・マンハッタン距離: 気温の絶対値の差を測る\n")
cat("- コサイン類似度: 気温変化のパターン（季節変動の形）を測る\n")
cat("- 相関係数: 気温変化の傾向（平均からのずれの関係）を測る\n")
cat("\n")
cat("あなたの考察をここに追加してください。\n")
```

**実行方法**:

```bash
Rscript exercise01_similarity.R
```

---

### 🤔 考察のポイント

#### 1. なぜ指標によって結果が異なるのか？

**ユークリッド距離・マンハッタン距離の特徴**:
- 気温の**絶対値**を比較
- 東京（冬5℃、夏27℃）とロンドン（冬5℃、夏18℃）は、気温の範囲が似ている
- → ロンドンが最も近い

**コサイン類似度・相関係数の特徴**:
- 気温の**変化パターン**を比較
- 東京と札幌は両方とも「冬寒く、夏暑い」という同じパターン
- 絶対的な気温は違うが、季節変動の形は似ている
- → 札幌が最も似ている

#### 2. シドニーはなぜ特殊か？

シドニーは南半球にあるため、季節が逆転しています。
- 日本の夏（7-8月）= シドニーの冬
- 日本の冬（1-2月）= シドニーの夏

相関係数で見ると、**負の相関**になるはずです。

#### 3. どの指標を使うべきか？

**目的による使い分け**:
- 「気温の絶対値が似ている都市を探す」→ ユークリッド距離
- 「季節変動のパターンが似ている都市を探す」→ 相関係数
- 「気候の特徴が似ている都市を探す」→ コサイン類似度

---

### 🎯 追加の演習（チャレンジ）

意欲的な学生は、以下の追加課題にも挑戦してみましょう。

#### チャレンジ1: ヒートマップの作成

4つの指標の結果を、それぞれヒートマップで可視化してください。

**ヒント**:
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.heatmap(euclidean_df, annot=True, fmt='.1f', cmap='YlOrRd')
plt.title('ユークリッド距離')
plt.show()
```

#### チャレンジ2: クラスタリング

階層的クラスタリングを使って、都市をグループ化してください。

**ヒント**:
```python
from scipy.cluster.hierarchy import dendrogram, linkage

# ユークリッド距離でクラスタリング
linkage_matrix = linkage(climate_df, method='ward')
dendrogram(linkage_matrix, labels=climate_df.index)
plt.show()
```

#### チャレンジ3: 自分のデータで実験

- 他の都市のデータを追加
- 降水量などの別の気候要素を分析
- 異なるドメインのデータ（株価、スポーツ成績など）で分析

---

## 3.5.7 まとめと学習チェックリスト

### 📚 本節のまとめ

本節では、1次元データの**類似度**と**非類似度**を測る4つの指標を学びました。

---

### 🎯 4つの指標の特徴まとめ

| 指標 | 種類 | 値の範囲 | 何を測るか | 使用場面 |
|:-----|:-----|:---------|:----------|:---------|
| **ユークリッド距離** | 非類似度 | 0以上 | 空間内の直線距離 | 一般的な距離測定 |
| **マンハッタン距離** | 非類似度 | 0以上 | 碁盤目状の距離 | 外れ値に強い、計算が速い |
| **コサイン類似度** | 類似度 | -1〜1 | ベクトルの向き | 文書類似度、高次元データ |
| **相関係数** | 類似度 | -1〜1 | 直線的な関係 | 統計分析、トレンド比較 |

---

### 🔍 指標の選び方

#### 距離を測りたい場合

**ユークリッド距離を使う場面**:
- 物理的な距離を測る
- 絶対値の差が重要
- 最も一般的な距離概念

**マンハッタン距離を使う場面**:
- 碁盤目状の構造
- 外れ値の影響を抑えたい
- 計算を高速化したい

#### 類似度を測りたい場合

**コサイン類似度を使う場面**:
- ベクトルの向き（方向）が重要
- スケール不変性が必要
- 文書の類似性判定
- 高次元データ

**相関係数を使う場面**:
- 変化のパターンが重要
- 統計的な関係を調べる
- トレンドの類似性
- 散布図との組み合わせ

---

### 💡 重要なポイント

#### 1. 指標によって結論が変わる

同じデータでも、使う指標によって「どれが似ているか」の結論が変わることがあります。**目的に応じて適切な指標を選ぶ**ことが大切です。

#### 2. 距離と類似度の違い

- **距離（非類似度）**: 小さいほど似ている
- **類似度**: 大きいほど似ている

混同しないよう注意しましょう。

#### 3. スケールの影響

- **ユークリッド距離・マンハッタン距離**: スケールに依存
- **コサイン類似度・相関係数**: スケール不変

#### 4. データフレームでの一括計算

実務では、複数データの全ペアを一度に計算することが多いです。RやPythonの便利な関数を活用しましょう。

---

### 🛠️ 実装の要点

#### R

```r
# ユークリッド距離
sum(diff^2)^0.5

# マンハッタン距離
sum(abs(diff))

# コサイン類似度
sum(A * B) / (sum(A * A)^0.5 * sum(B * B)^0.5)

# 相関係数
cor(A, B)

# データフレーム一括計算
my_df %>% proxy::dist("Euclidean")
my_df %>% proxy::simil("cosine")
```

#### Python

```python
# ユークリッド距離
distance.euclidean(A, B)

# マンハッタン距離
distance.cityblock(A, B)

# コサイン類似度（1から引く）
1 - distance.cosine(A, B)

# 相関係数
pearsonr(A, B)[0]
# または
1 - distance.correlation(A, B)

# データフレーム一括計算
distance.cdist(my_df, my_df, metric='euclidean')
```

---

### 🔗 次のステップ

本節で学んだ類似度・非類似度の概念は、以下の発展的なトピックの基礎となります。

1. **クラスタリング（13章）**: 似たデータをグループ化
2. **推薦システム**: ユーザーやアイテムの類似性に基づく推薦
3. **異常検知**: 通常パターンと大きく異なるデータの発見
4. **次元削減**: 高次元データの可視化
5. **機械学習**: k近傍法など、距離ベースのアルゴリズム

---

### ✅ 自己チェックリスト

本節の学習内容を確認しましょう。できた項目にチェック☑️を入れてください。

---

#### A. 環境構築と基本操作 (8項目)

- [ ] 推奨ディレクトリ（/home/datasci/work）で作業できる
- [ ] 仮想環境（venvc）を起動できる
- [ ] Pythonファイルを作成・実行できる（touch, python）
- [ ] Rファイルを作成・実行できる（touch, Rscript）
- [ ] NumPyとSciPyがインストールされている
- [ ] Rのtidyverseとproxyパッケージがインストールされている
- [ ] VS Codeでプログラムを編集できる
- [ ] ターミナルで実行結果を確認できる

---

#### B. 基本概念の理解 (12項目)

- [ ] 類似度と非類似度の違いを説明できる
- [ ] 距離（非類似度）は小さいほど似ていることを理解している
- [ ] 類似度は大きいほど似ていることを理解している
- [ ] n次元ベクトルの概念を理解している
- [ ] 3次元空間での距離のイメージを持っている
- [ ] 4次元以上でも指標が使えることを知っている
- [ ] 指標によって結論が変わることを理解している
- [ ] 距離行列の概念を理解している
- [ ] 対称行列の性質を理解している
- [ ] スケール不変性の意味を理解している
- [ ] 相関と因果の違いを理解している
- [ ] 三角不等式の概念を知っている

---

#### C. ユークリッド距離 (8項目)

- [ ] ユークリッド距離の定義を説明できる
- [ ] ピタゴラスの定理との関係を理解している
- [ ] Rで手動計算できる（sum, ^2, ^0.5）
- [ ] Pythonで手動計算できる（np.sum, **2, **0.5）
- [ ] Python の distance.euclidean() を使える
- [ ] 2点間の距離を計算できる
- [ ] どんな場面で使うべきか説明できる
- [ ] サンプルプログラムを実行して結果を確認した

---

#### D. マンハッタン距離 (8項目)

- [ ] マンハッタン距離の定義を説明できる
- [ ] タクシー距離、シティブロック距離の別名を知っている
- [ ] ユークリッド距離との違いを説明できる
- [ ] Rで計算できる（sum, abs）
- [ ] Python の distance.cityblock() を使える
- [ ] 碁盤目状の移動のイメージを持っている
- [ ] どんな場面で使うべきか説明できる
- [ ] サンプルプログラムを実行して結果を確認した

---

#### E. コサイン類似度 (10項目)

- [ ] コサイン類似度の定義を説明できる
- [ ] ベクトルの向きを測る指標であることを理解している
- [ ] 値の範囲（-1〜1）とその意味を理解している
- [ ] 内積の概念を理解している
- [ ] ベクトルの長さ（ノルム）を計算できる
- [ ] Rで手動計算できる
- [ ] Python で 1 - distance.cosine() を使える
- [ ] スケール不変性を理解している
- [ ] コサイン距離が厳密な距離でないことを知っている
- [ ] サンプルプログラムを実行して結果を確認した

---

#### F. 相関係数 (10項目)

- [ ] 相関係数の定義を説明できる
- [ ] 値の範囲（-1〜1）とその意味を理解している
- [ ] 正の相関、負の相関、無相関を説明できる
- [ ] 平均値と偏差の概念を理解している
- [ ] R の cor() を使える
- [ ] Python の pearsonr() を使える
- [ ] 相関と因果関係は別であることを理解している
- [ ] 直線関係のみを測る指標であることを理解している
- [ ] 外れ値の影響を受けることを知っている
- [ ] サンプルプログラムを実行して結果を確認した

---

#### G. データフレームでの一括計算 (10項目)

- [ ] データフレームの構造を理解している
- [ ] Rでデータフレームを作成できる
- [ ] Pythonでデータフレームを作成できる
- [ ] R の proxy::dist() を使える
- [ ] R の proxy::simil() を使える
- [ ] Python の distance.cdist() を使える
- [ ] 距離行列の読み方を理解している
- [ ] 複数データの全ペアを一括計算できる
- [ ] 最も類似したペアを見つけることができる
- [ ] サンプルプログラムを実行して結果を確認した

---

#### H. プログラミングスキル (12項目)

- [ ] Python: NumPy配列を作成できる（np.array）
- [ ] Python: SciPyの関数をインポートできる
- [ ] Python: f-stringで結果を表示できる
- [ ] R: ベクトルを作成できる（c()）
- [ ] R: パイプ演算子（%>%）を使える
- [ ] R: print, paste で結果を表示できる
- [ ] コメントを適切に書ける
- [ ] 変数に意味のある名前を付けられる
- [ ] 実行結果を確認できる
- [ ] エラーメッセージを読んで対処できる
- [ ] プログラムを段階的にデバッグできる
- [ ] 他人が読みやすいコードを書ける

---

#### I. AI協働スキル (10項目)

- [ ] GitHub Copilot Chatを起動できる
- [ ] 適切なプロンプトを書ける
- [ ] 生成されたコードを理解してから使う
- [ ] わからない部分をCopilotに質問できる
- [ ] エラーメッセージをCopilotに相談できる
- [ ] コメントを書いてコード補完を活用できる
- [ ] 生成されたコードを検証できる
- [ ] Copilotの提案を批判的に評価できる
- [ ] AIに丸投げせず、自分で考えることを忘れない
- [ ] AI協働学習の適切なバランスを理解している

---

#### J. 統合演習 (8項目)

- [ ] 演習課題を最後まで実行した
- [ ] 4つの指標を全て計算できた
- [ ] 各指標の結果を比較できた
- [ ] 指標による結論の違いを考察した
- [ ] 結果の妥当性を検証した
- [ ] ヒートマップを作成できる（オプション）
- [ ] 自分のデータで実験した（オプション）
- [ ] クラスタリングを試した（オプション）

---

#### K. 応用と発展 (6項目)

- [ ] 実データで類似度分析ができる
- [ ] 目的に応じて適切な指標を選べる
- [ ] 結果を可視化できる
- [ ] 結果を解釈して説明できる
- [ ] 次の学習ステップ（クラスタリングなど）を知っている
- [ ] 類似度の概念を他の分野に応用できる

---

### 📊 達成度評価

チェックした項目数を数えて、自分の達成度を確認しましょう。

| チェック数 | 達成度 | コメント |
|:----------|:-------|:---------|
| **80-102** | 🌟🌟🌟 優秀 | 素晴らしい！本節を完全に理解しています |
| **60-79** | 🌟🌟 良好 | よくできました。さらに実験を重ねましょう |
| **40-59** | 🌟 合格 | 基本は押さえています。復習で理解を深めましょう |
| **20-39** | △ 要復習 | もう一度サンプルプログラムを実行しましょう |
| **0-19** | ✗ 未達 | 基礎から丁寧に学び直しましょう |

---

### 🎯 復習のポイント

#### チェックが少なかった分野を重点的に復習しましょう

**A~B（基本）が不足**:
- 環境設定を再確認
- 用語の定義を復習
- サンプルプログラムを1つずつ実行

**C~F（各指標）が不足**:
- 該当セクションを読み直す
- 手動計算を紙に書いてみる
- サンプルプログラムを改造して実験

**G~H（実装）が不足**:
- コードを写経して実行
- エラーが出たら原因を調べる
- GitHub Copilotに質問

**I（AI協働）が不足**:
- Copilot活用ガイドを実践
- プロンプト例を試す
- 自分でプロンプトを考えてみる

**J（演習）が不足**:
- 演習課題に再挑戦
- 追加のチャレンジ課題に取り組む
- 自分のデータで実験

---

### 📖 さらに学びたい人へ

#### 推奨される参考資料

1. **本書の関連節**:
   - 13.2節: クラスタ分析（本節の内容を応用）
   - 7.4節: 予測精度の評価（RMSE、決定係数）

2. **オンライン資料**:
   - SciPy公式ドキュメント: distance関数の詳細
   - R proxy パッケージのドキュメント

3. **発展的なトピック**:
   - 他の距離指標（ミンコフスキー距離、ジャッカード距離）
   - 高次元データでの距離の性質（次元の呪い）
   - 距離学習（metric learning）

---

### 🎓 最後に

データサイエンスにおいて、「似ている」を定量化する能力は非常に重要です。本節で学んだ4つの指標は、今後のデータ分析の基礎となります。

**大切なこと**:
1. **完璧を目指さない**: 全ての項目にチェックが入らなくても大丈夫です
2. **実践を重ねる**: サンプルを動かし、自分のデータで試すことが最高の学習法
3. **AIと協働する**: GitHub Copilotを活用しながら、自分で考えることを忘れずに
4. **疑問を大切に**: わからないことがあれば、それが学びのチャンス

本節の学習、お疲れさまでした！

次の節では、これらの類似度の概念を実際のデータ分析でどう活用するかを学んでいきます。🚀
